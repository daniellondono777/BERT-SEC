{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hQtpbONZidF0"
      },
      "outputs": [],
      "source": [
        "API_KEY=''\n",
        "filings = '/content/drive/MyDrive/BERT-SEC'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "7p3Y2Z-wi-NT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import time\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score\n",
        "import plotly.express as px\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "o-costbizcr4"
      },
      "outputs": [],
      "source": [
        "headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36' }\n",
        "cik_codes_json = requests.get('https://www.sec.gov/files/company_tickers.json', headers=headers).json()\n",
        "companies = pd.DataFrame.from_dict(cik_codes_json.values())\n",
        "\n",
        "def get_industry(ticker):\n",
        "  r = requests.get('https://www.alphavantage.co/query?function=OVERVIEW&symbol={s}&apikey={k}'.format(s=ticker, k=API_KEY))\n",
        "  return r.json()\n",
        "\n",
        "def get_ticker(cik):\n",
        "  ticker = companies[companies['cik_str'] == cik]['ticker']\n",
        "  return ticker\n",
        "\n",
        "def apply_ticker_get_industry():\n",
        "  ciks = [int(i.split('_')[0]) for i in os.listdir(filings)]\n",
        "  mapping = []\n",
        "  for c in ciks:\n",
        "    t = str(get_ticker(c).iloc[0])\n",
        "    mapping.append(get_industry(t))\n",
        "  return mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "8TpCfoTBloeY"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Joins all the datasets. There are\n",
        "#\n",
        "def join_data():\n",
        "  files = [f for f in os.listdir(filings)]\n",
        "  df_array = [pd.read_csv(filings + '/' + f) for f in files]\n",
        "  all_columns = list(set().union(*(df.columns for df in df_array)))\n",
        "  filled_dataframes = [df.reindex(columns=all_columns, fill_value=0) for df in df_array]\n",
        "  stacked_df = pd.concat(filled_dataframes, ignore_index=True)\n",
        "\n",
        "  return stacked_df\n",
        "\n",
        "#\n",
        "# Select features\n",
        "# params:\n",
        "#   - threshold: The % of zeros that a feature can hold maximum\n",
        "#\n",
        "def get_features(df, threshold):\n",
        "  threshold = len(df) * threshold\n",
        "  zero_counts = (df == 0).sum()\n",
        "  columns = zero_counts[zero_counts <= threshold].index.to_list()\n",
        "  return df[columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "4-c8V-i2wK2K"
      },
      "outputs": [],
      "source": [
        "def perform_pca_select_features_df(df, n_components=None):\n",
        "  X = df.values\n",
        "\n",
        "  pca = PCA(n_components=n_components)\n",
        "  X_pca = pca.fit_transform(X)\n",
        "\n",
        "  explained_var = pca.explained_variance_ratio_\n",
        "\n",
        "  cumulative_var = 0\n",
        "  selected_components = 0\n",
        "  for i, var in enumerate(explained_var):\n",
        "      cumulative_var += var\n",
        "      if cumulative_var >= 0.95:\n",
        "          selected_components = i + 1\n",
        "          break\n",
        "\n",
        "  selected_X = X_pca[:, :selected_components]\n",
        "\n",
        "  return selected_X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "wduAVEFRDSGP"
      },
      "outputs": [],
      "source": [
        "def build_lof_model(data, n_neighbors=20, contamination=0.1):\n",
        "  scaler = StandardScaler()\n",
        "  scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "  lof_model = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination)\n",
        "\n",
        "  lof_model.fit(scaled_data)\n",
        "\n",
        "  return lof_model, scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "0-pJBVnyGY8y"
      },
      "outputs": [],
      "source": [
        "def evaluate_lof_silhouette(lof_model, dataframe):\n",
        "  lof_scores = -lof_model.negative_outlier_factor_\n",
        "\n",
        "  silhouette = silhouette_score(dataframe, lof_scores)\n",
        "\n",
        "  return silhouette"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "URTmaVfHDW7i"
      },
      "outputs": [],
      "source": [
        "def visualize_lof_scores(lof_model, dataframe):\n",
        "  lof_scores = -lof_model.negative_outlier_factor_\n",
        "  plt.scatter(range(len(dataframe)), lof_scores, c='blue', s=20, label='LOF scores')\n",
        "  plt.xlabel('Data Points')\n",
        "  plt.ylabel('LOF Scores')\n",
        "  plt.title('Local Outlier Factor (LOF) Scores')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2d__GKdKH5UM"
      },
      "outputs": [],
      "source": [
        "def cluster_build_plot(df_p, n_clusters, features):\n",
        "    X = df_p[features]\n",
        "    kmeans = KMeans(\n",
        "        n_clusters=n_clusters,\n",
        "        init='k-means++',\n",
        "        n_init= 35,\n",
        "        max_iter=300,\n",
        "        tol=1e-4,\n",
        "        verbose=0,\n",
        "        random_state=None,\n",
        "        copy_x=True,\n",
        "        algorithm='elkan')\n",
        "    kmeans.fit(X)\n",
        "\n",
        "    labels = kmeans.predict(X)\n",
        "\n",
        "    df['Cluster'] = labels\n",
        "\n",
        "    if len(features) == 2:\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.scatter(df[features[0]], df[features[1]], c=labels, cmap='viridis', marker='o', edgecolors='black')\n",
        "        plt.title('Cluster Plot')\n",
        "        plt.xlabel(features[0])\n",
        "        plt.ylabel(features[1])\n",
        "        plt.colorbar(label='Cluster')\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"Plotting is available only for 2D data.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cluster_build_plot_3d(df_p, n_clusters, features):\n",
        "    X = df_p[features]\n",
        "\n",
        "    kmeans = KMeans(n_clusters=n_clusters)\n",
        "    kmeans.fit(X)\n",
        "\n",
        "    labels = kmeans.predict(X)\n",
        "\n",
        "    df['Cluster'] = labels\n",
        "\n",
        "    fig = px.scatter_3d(df, x=features[0], y=features[1], z=features[2], color='Cluster', symbol='Cluster')\n",
        "    fig.update_layout(title='Cluster Plot in 3D', scene=dict(\n",
        "        xaxis_title=features[0],\n",
        "        yaxis_title=features[1],\n",
        "        zaxis_title=features[2]\n",
        "    ))\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def top_correlated_pairs(df_p, n):\n",
        "    corr_matrix = df_p.corr().abs()\n",
        "    mask = ~pd.np.eye(corr_matrix.shape[0], dtype=bool)\n",
        "\n",
        "    upper_tri = corr_matrix.where(mask)\n",
        "    stacked_corr = upper_tri.stack().sort_values(ascending=False)\n",
        "    unique_pairs = stacked_corr[stacked_corr.index.map(lambda x: x[0] < x[1])]\n",
        "    top_pairs = unique_pairs.head(n)\n",
        "\n",
        "    return top_pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "ccd205b63dcc03def19ac0ba8535a9f8bab38b9a067bfe4e6fe86f2cb1e97b9c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
